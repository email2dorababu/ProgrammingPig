PG 33
Introduction To PIG LATIN:
Advanced features are covered in Chapter 6.
----------------------------
Basics: 
Pig latin is data flow language.
Each processing step results in new data set, or relation.
eg. input = load 'data' -  input is name of the relation resulting from loading of data set 'data'.
Relation name is called ALIAS.
Relation names are not variables. Once made, assignment is permanent. But you can reuse the names.

A = load 'NYSE_dividends' (exchange, symbol, date, dividends);

Field Names - dividends,symbol.
A - relation name(alias).

The fields contain different value for each record , but you cannot assign values to them.
Relation and filed names should start with alphabetic character. can contain alphanumeric and _(underscore).

Case Sensitivity:
-------------------
UDF,Relation, field names are case sensitive. e.g COUNT is not the same as count UDF.
Keyworkds are not case sensive . e.g LOAD is equivalent to load.

Comments -SQL style --,/* */
---------------------------------
Input and Output:

LOAD - 
------------
First step to any data flow is to specify your input. Pig latin we specify the input with the 'LOAD' statement.
Defaults are - load looks data on HDFS , tab delimited, default load function is PigStorage.
[Here it is FUNCTION,so u can pass arguments]
Default incase of relative paths are home directory on HDFS, /users/yourlogin . 
you can specify URLs e.g. hdfs://nn.acme.com/data/examples/NYSE_dividends, here the data is red from HDFS in
nn.acme.com as a Namenode.

Usually most data wont be tab delimited, and you may also load data from storages other than HDFS. 
You specify the function for loading your data with the 'USING' clause.
e.g divs=load 'NYSE_dividends' using HBaseStorage();  using the loader for Hbase.
You can pas arguments to your load function via USING clause.
e.g divs=load 'NYSE_dividends' using PigStorage(',') - for comma separated text data.

Load stmt also can have 'AS' clause, allows you to specify the schema of the data you are loading.
divs=load 'NYSE_dividends' as (exchange,symbol,date,dividends);
You can specify file or directory as input. If directory then pig will read all the files in directory, 
also it reads sub directories in the input directory.

PG-35:
PigStorage and TextLoader are two built-in Pig load functions that operates on HDFS files, supports globs.
GLOBS, you can read multiple files under different directories and few files under a single directory.
Glob in Hadoop 0.20 -Table 5.1:
? , *, [abc] matches single char from char set a,b,c, [a-z] matches single char from char range(a..z) inclusive.
[^abc] - single char not matching a,b,c. ^ must occur immediately to the right of the opening bracket.
[^a-z], \c removes any special meaning of character c. 
{ab,cd} - matching string from string set{ab,cd}
--------------------
STORE :
  once you finished processing your data, you will want to write it out somewhere. STORE statement stores your data on HDFS
  in TAB delimited file using PigStorage function. you can specify path or URL. Default store function is PigStorage.
  store processed into '/data/examples/processed';
By USING clause, you can use a different store function.
 store processed into 'processed' using HbaseStorage();
 You can pass arguments to your store function. e.g 
 store processed into 'processed' using PigStorage(',');
 Here processed will be a directory, not a single file. 
 the no of part files created depends on the parallelism of the last job before the STORE.
 For maponly job, o/p depends on no of maps , controlled by Hadoop not PIG.
 if it has reduces, the o/p part files determined by the paralel level set for that job.
 ----------------------
DUMP:
 If we want ot see the output on screen instead of storing it,useful for debugging and prototyping sesssions.
 DUMP directs the output of your script to your screen.
 dump processed;
 
 maps are surrouned by [],bags {}, tuples (). missings values are rep by nulls and fields are separated by commas.
 ------------------------------------
 
Relational Operators  PG 37:
  These relational operators are the MAIN TOOLS PigLatin provides to operate on your data.
  They allows you to transform data by SORTING,GROUPING,JOINING,PROJECTION and filtering.
  Basics are covered here. advanced in next chapters.
  ----
FOREACH - 
  foreach - takes a SET OF EXPRESSONS and applies to EVERY RECORD in the data pipeline, hence the name foreach.
  For each is the Projection operatior in PIG.
  e.g to select only few fields,
  B=foreach A generate user,id;
  
  Expressions in FOREACH: pg-37
  Foreach supports an array of expressions.
  simple expression is constants and field references.
  field refereneces are by name or by position. Positional references are preceded by $ sign, starts from ZERO.
  e.g- gain=foreach prices generate close-open;   - expression using field names
  gain1=foreach prices generate $6-$3;  - expression using positional references.
  
  both gain,gain1 contain same value. postional ref are useful when we donot know the schema.
  You can use below things to reference fields:
  * - to access all fields in a tuple.
  .. - to refer range of fields. useful when we have many fields.
  
  ----------------
prices = load 'NYSE_daily' as (exchange, symbol, date, open,
high, low, close, volume, adj_close);
beginning = foreach prices generate ..open; -- produces exchange, symbol, date, open
middle = foreach prices generate open..close; -- produces open, high, low, close
end = foreach prices generate volume..; -- produces volume, adj_close
  -------------------
Standard arithmetic operations as expressions.
+,-,*, / 
NOTE - these operators return values of their own type .. e.g 5/2 is 2 where as 5.0/2.0 is 2.5.
For integers modulo operator % is supported.
- negative (unary operator) supported for int and flots. Precedence rules are obeyed in pig.
NULLS are viran  for all arithmatic operators. 
x+null = null for all values of x.

BINCOND  - binary condition operator- Begins with a boolean test, followed by ? then value to be returned when test is true
then : colon, finally the value to be returned if the test is false. If the test returns null, bincond returns null. 
Both value args i.e returns values in case of true/false must be of same type.
2 == 2 ? 1 : 'fred' -- returns error, since both values are of diff type.
2 == 2 ? 1 : 4 --returns 1
2 == 3 ? 1 : 4 --returns 4
null == 2 ? 1 : 4 -- returns null

PG - 38:
To extract data from complex types, use projection operators, Maps #(hash) followed by the NAME of the KEY as a string
(i.e with quotes surroundign the name)
eg.  avg=foreach bball generate bat#'batting_average';  non exisintg fields returns null.
Tuple projection is done using .(dot operator), fields can be referenced by name or position.
A = load 'input' as (t:tuple(x:int, y:int));
B = foreach A generate t.x, t.$1;    NOTE - non existing postional field returns null, non exisiting field referenced by
name will produce an error.

BAG - projection is not as straight forward as map and tuple projection. Bags donot gurantee any order in which their tuples
are stored, so allowing a projection of tuples inside bag would not be meaningful.
Instead you can project fields of bag to create a new bag with only those fields.
A = load 'input' as (b:bag{t:(x:int, y:int)});
B = foreach A generate b.x;
This will produce a new bag whose tuples have only the field x in them. You can project multiple fields in a bag by 
surrounding the fields with parentheses and separating them
by commas:
A = load 'input' as (b:bag{t:(x:int, y:int)});
B = foreach A generate b.(x, y);

here above b.x is not a scalar, it is a bag. 

A = load 'foo' as (x:chararray, y:int, z:int);
B = group A by x; -- produces bag A containing all the records for a given value of x
C = foreach B generate SUM(A.y + A.z);  -- will throw error. because a.y and b.y are bags.
so use 
A = load 'foo' as (x:chararray, y:int, z:int);
A1 = foreach A generate x, y + z as yz;
B = group A1 by x;
C = foreach B generate SUM(A1.yz);
-----------------
UDFS in Foreach - User defined functions can be invoked in FOREACH.
PG - 39:
These are called eavluation functions or EVAL functions. because they are part of foreach statement.
These udfs take one record at a time and produce one output.
NOTE - either the input or the output can be bag, so the one record can contain a bag of records.
-- udf_in_foreach.pig
divs = load 'NYSE_dividends' as (exchange, symbol, date, dividends);
--make sure all strings are uppercase
upped = foreach divs generate UPPER(symbol) as symbol, dividends;
grpd = group upped by symbol; --output a bag upped for each value of symbol
--take a bag of integers, produce one result for each group
sums = foreach grpd generate group, SUM(upped.dividends);

Eval funcs can take * as argument, which passes the entire record to the function. they can also be invoked with no args also
--------------------
Naming Fields in FOREACH: 
 The result of each for each stmt is a new tuple, usually with a diff schema than the tuple that was an input to foreach.
 NOTE for fields that are simple projections with no other operations applied, pig keeps the same name as before 
divs = load 'NYSE_dividends' as (exchange:chararray, symbol:chararray,date:chararray, dividends:float);
sym = foreach divs generate symbol;
describe sym;
sym: {symbol: chararray}

Now the expression is not a simple projection, pig doesnot assign a name to the field.here we can access the field only by 
positional parameter($). you can assign a name to the field with 'as' clause.
in_cents = foreach divs generate dividends * 100.0 as dividend, dividends * 100.0;
describe in_cents;
in_cents: {dividend: double,double}
----------------------------
FILTER -   PG 40.
  filter stmt allows you to select which records will be retained in your data pipeline.
  FILTER contains a predicate. the predicate evaluates to true for a given record, that record will passed down the pipeline.
  otherwise it will not.
  predicates can contain ==(equality), !=,>,>=,<,<= for comparing any scalar data type. == and != to compare maps and tuples.
  
  To use with tuples, bot tuples must have the same schema or no schema. None of the equality operators can be applied to bag
  
  for Chararrays- you can test to match with the regular expression:
  startswith= filter divs by symbol matches 'CM.*';   --note pig uses Java's regular expession formats.
  E.G to match with fred, you should use .*fred.* and not 'fred'. later will match only the chararray 'fred'
  notstartswithcm = filter divs by not symbol matches 'CM.*'; -- chararrays that do not match a reg exp with NOT.
  PG - 41:
  Combine multiple predicates into one using boolean operator and/or. and reverse the boolean outcome by NOT.
  
  As is standard, the precedence of Boolean operators, from highest to lowest, is not, and,
or. Thus a and b or not c is equivalent to (a and b) or (not c).


  




